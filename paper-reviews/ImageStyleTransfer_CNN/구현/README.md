# ğŸ§ ë…¼ë¬¸ êµ¬í˜„: Image Style Transfer Using Convolutional Neural Networks

![result](../assets/result2.jpg)  

ë…¼ë¬¸ ë§í¬: https://arxiv.org/abs/1508.06576

ë°œí‘œ í•™íšŒ/ì—°ë„: CVPR 2016 (IEEE Conference on Computer Vision and Pattern Recognition)

ë…¼ë¬¸ ì €ì: Leon A. Gatys, Alexander S. Ecker, Matthias Bethge

------
### Overview

ìœ„ ë…¼ë¬¸ì—ì„œëŠ” CNNì„ ì´ìš©í•˜ì—¬ ì‚¬ì§„ì—ì„œ contentì™€ styleì„ ì¶”ì¶œí•´ë‚´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë°©ì‹ì„ ì†Œê°œí•˜ì˜€ìŠµë‹ˆë‹¤

ì²˜ìŒìœ¼ë¡œ ë…¼ë¬¸ì„ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤ ë…¼ë¬¸ì„ ì½ê³  ì´í•´í•˜ë©° ê·¸ê²ƒì„ ì½”ë“œë¡œ ì˜®ê¸°ëŠ”ë°ê¹Œì§€ ë§ì€ ì‹œê°„ì´ ê±¸ë¦° ê²ƒ ê°™ìŠµë‹ˆë‹¤ ì²«ë²ˆì§¸ë¡œ êµ¬ì¡°ë¥¼ ë‚˜ëˆ„ëŠ” ê²ƒì— ëŒ€í•´ ê³ ë¯¼í–ˆìŠµë‹ˆë‹¤
- `models.py` : ë…¼ë¬¸ì— ë‚˜ì˜¨ ì•„í‚¤í…ì²˜ êµ¬í˜„  
- `loss.py` : style/content loss êµ¬í˜„  
- `train.py` : ì „ì²´ í•™ìŠµ ë£¨í”„

ê´€ìŠµëŒ€ë¡œë¼ë©´ 'dataset.py'ë„ ìˆì–´ì•¼í•˜ì§€ë§Œ ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” datasetì´ë¼ê³  í•˜ê¸°ì—” ì˜¤ë¡œì§€ contentì‚¬ì§„1ì¥, styleì‚¬ì§„ 1ì¥ë§Œì´ í•„ìš”í–ˆê¸°ì— í¬í•¨í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤  
ì¶”ê°€ë¡œ ì´ ë…¼ë¬¸ì„ reviewí•˜ê¸°ë¡œ í•œ ì´ìœ ëŠ” ë…¼ë¬¸ì„ êµ¬í˜„í•œë’¤ ê²°ê³¼ë¬¼ì´ í•œ ëˆˆì— ë³´ì´ë©° cnnì„ ì´ìš©í•˜ì—¬ ì¶”ìƒì ì˜ë¯¸ì¸ styleì„ êµ¬í˜„í•´ëƒˆë‹¤ëŠ” ì ì´ ë§¤ìš° í¥ë¯¸ë¡œì› ê¸°ì— ì„ íƒí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤

-----------

## Models.py

ë…¼ë¬¸ 2. Deep image representationì„ ì‚´í´ë³´ë©´  
>**"The results presented below were generated on the ba
sis of the VGG network"**  
>-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]

>**"We used the feature
 space provided by a normalised version of the 16 convo
lutional and 5 pooling layers of the 19-layer VGG network"**  
>-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]

ì €ìëŠ” <strong>VGG19 model</strong>ì„ ì‚¬ìš©í–ˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤.
ê·¸ì¤‘ì—ì„œë„ <strong>feature map</strong>ì„ ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

>**"We reconstruct the input image from from layers â€˜conv1 2â€™ (a),
 â€˜conv2 2â€™ (b), â€˜conv3 2â€™ (c), â€˜conv4 2â€™ (d) and â€˜conv5 2â€™ (e) of the original VGG-Network.k"**  
>-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]

>**" We reconstruct
 the style of the input image from a style representation built on different subsets of CNN layers ( â€˜conv1 1â€™ (a), â€˜conv1 1â€™ and â€˜conv2 1â€™
 (b), â€˜conv1 1â€™, â€˜conv2 1â€™ and â€˜conv3 1â€™ (c), â€˜conv1 1â€™, â€˜conv2 1â€™, â€˜conv3 1â€™ and â€˜conv4 1â€™ (d), â€˜conv1 1â€™, â€˜conv2 1â€™, â€˜conv3 1â€™, â€˜conv4 1â€™
 and â€˜conv5 1â€™ (e)"**  
>-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]

ì–´ë–¤ í”¼ì³ë§µì„ ì‚¬ìš©í–ˆëŠ”ì§€ ê¶ê¸ˆí•´ì§ˆ ë¬´ë µ, ë…¼ë¬¸ ì† ìœ„ ë¬¸ì¥ì—ì„œ <code>conv(a)_(b)</code>ì™€ ê°™ì€ ë§ì´ ë‚˜ì˜¤ëŠ”ë°, VGG19 êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ë©´ ê·¸ ì˜ë¯¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<div style="display: flex; align-items: flex-start;">
  <img src="../assets/paper3.jpg" width="300" style="margin-right: 20px;">
</div>

conv(a)_(b)ëŠ” ì €ìê°€ íŠ¹ì • conv ë ˆì´ì–´ ìœ„ì¹˜ë¥¼ ëª…ì‹œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ  
- `a` : ë¸”ë¡ë²ˆí˜¸(VGGì—ì„œ max poolingìœ¼ë¡œ ë‚˜ëˆ„ë‹ˆ ë¸”ë¡ë“¤)  
- `b` : ê·¸ ë¸”ë¡ ì•ˆì—ì„œì˜ convë ˆì´ì–´ ìˆœì„œ  

ë¼ëŠ”ê±¸ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤

ê·¸ë˜ì„œ ì €ëŠ” styleì‚¬ì§„ì—ì„œ conv1_1, conv2_1, conv3_1, conv4_1, conv5_1ì„, contentì‚¬ì§„ì—ì„œ conv4_2ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤ pytorch vgg19ëª¨ë¸ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ conv layerë¥¼ ì •ë¦¬í•˜ì˜€ê³  vgg19ë¥¼ í†µê³¼í•˜ë‹¤ê°€ ì›Œì›í•˜ëŠ” convë¥¼ ë§Œë‚˜ê²Œë˜ë©´ í•´ë‹¹ feature mapì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ ì½”ë“œë¥¼ ì œì‘í•˜ì˜€ìŠµë‹ˆë‹¤

```ptyhon
conv = {
    'conv1_1' : 0, #style featuremap layer 
    'conv2_1' : 5, #style featuremap layer 
    'conv3_1' : 10, #style featuremap layer 
    'conv4_1' : 19, #style featuremap layer 
    'conv5_1' : 28, #style featuremap layer 
    'conv4_2' : 21, #content featuremap layer
}
```

### Why CNN?

<div style="display: flex; align-items: flex-start;">
  <img src="../assets/paper4.jpg" width="400" style="margin-right: 20px;">
</div>
-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]
<br><br><br>

ê·¸ë¦¬ê³  ì´ ì‚¬ì§„ê³¼ í•¨ê»˜ ê¸€ì—ì„œ cnnì„ ì‚¬ìš©í•œ ì´ìœ ë¥¼ ë“¤ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤  <br>

>**We find that reconstruction from lower layers is
 almost perfect (aâ€“c). In higher layers of the network, detailed pixel information is lost while the high-level content of the image is preserved(d,e)**  
>-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]

>**This creates images that match the style of a given image on an increasing scale while discarding information of the global arrangement of the scene.**  
>-[Gatys et al., Image Style Transfer Using CNNs, CVPR 2016]

contentë¥¼ ë½‘ê¸°ìœ„í•´ cnnì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ high-levelì—ì„œ ì„¸ë¶€ì ì¸ í”½ì…€ì •ë³´ê°€ ì†ì‹¤ë˜ì§€ë§Œ ì´ë¯¸ì§€ì˜ ê³ ìˆ˜ì¤€ ë‚´ìš©ì„ ë³´ì¡´í•´ëƒˆê³   
styleì€ cnnì„ ì‚¬ìš©í•¨ìœ¼ë¡° ì£¼ì–´ì§„ ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼ì„ ì ì  ë” í° ìŠ¤ì¼€ì¼ì—ì„œ ì¼ì¹˜ì‹œí‚¤ëŠ” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚´, ì¥ë©´ì˜ ì „ì²´ êµ¬ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œí•¨ìœ¼ë¡œì¨ styleì„ ë½‘ì•„ë‚¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤  
ì´ë ‡ê²Œ cnnì´ contentì™€ styleì„ ë½‘ì•„ëƒˆê¸°ì— ì´ëŸ¬í•œ ë…¼ë¬¸ì´ ë‚˜ì˜¬ ìˆ˜ ìˆì—ˆì§€ ì•Šì•˜ë‚˜ ìƒê°ë©ë‹ˆë‹¤
<br><br><br>

### ì•ì„  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìˆ˜ë„ì½”ë“œ ë§Œë“¤ê¸°

```python
class StyleTransfer:

    ì´ˆê¸°í™”í•  ë•Œ:
        VGG19 ëª¨ë¸ ë¶ˆëŸ¬ì˜´ (pretrained)
        VGG19ì—ì„œ feature ì¶”ì¶œ ë¶€ë¶„ë§Œ ë½‘ìŒ
        ìŠ¤íƒ€ì¼ ì¶”ì¶œì— ì“¸ conv ë ˆì´ì–´ ë²ˆí˜¸ë“¤ ì •í•¨ (ì˜ˆ: conv1_1, conv2_1 ...)
        ì»¨í…ì¸  ì¶”ì¶œì— ì“¸ conv ë ˆì´ì–´ ë²ˆí˜¸ ì •í•¨ (ì˜ˆ: conv4_2)

    forward í•¨ìˆ˜ (ì´ë¯¸ì§€, ëª¨ë“œ):
        featuresë¼ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë§Œë“¦

        ë§Œì•½ ëª¨ë“œê°€ 'style'ì´ë©´:
            VGG19 ë ˆì´ì–´ë¥¼ ì°¨ë¡€ëŒ€ë¡œ ì§€ë‚˜ê°€ë©´ì„œ
                í˜„ì¬ ë ˆì´ì–´ ë²ˆí˜¸ê°€ ìŠ¤íƒ€ì¼ ë ˆì´ì–´ ëª©ë¡ì— ìˆìœ¼ë©´
                    í•´ë‹¹ ë ˆì´ì–´ ì¶œë ¥ê°’ì„ featuresì— ì¶”ê°€

        ë§Œì•½ ëª¨ë“œê°€ 'content'ì´ë©´:
            VGG19 ë ˆì´ì–´ë¥¼ ì°¨ë¡€ëŒ€ë¡œ ì§€ë‚˜ê°€ë©´ì„œ
                í˜„ì¬ ë ˆì´ì–´ ë²ˆí˜¸ê°€ ì»¨í…ì¸  ë ˆì´ì–´ ëª©ë¡ì— ìˆìœ¼ë©´
                    í•´ë‹¹ ë ˆì´ì–´ ì¶œë ¥ê°’ì„ featuresì— ì¶”ê°€

        ìµœì¢…ì ìœ¼ë¡œ features ë°˜í™˜
```
<br><br><br>

### model ë§Œë“¤ê¸°

```python
#import
import torch
import torch.nn as nn
from torchvision.models import vgg19

conv = {
    'conv1_1' : 0, #style featuremap layer 
    'conv2_1' : 5, #style featuremap layer 
    'conv3_1' : 10, #style featuremap layer 
    'conv4_1' : 19, #style featuremap layer 
    'conv5_1' : 28, #style featuremap layer 
    'conv4_2' : 21, #content featuremap layer
}

class StyleTransfer(nn.Module):
    def __init__(self,):
        super(StyleTransfer, self).__init__()
        #TODO: VGG19 load
        self.vgg19_model = vgg19(pretrained = True)
        self.vgg19_features = self.vgg19_model.features

        #TODO: conv layer ë¶„ë¦¬
        self.style_layer = [conv['conv1_1'], conv['conv2_1'], conv['conv3_1'], conv['conv4_1'], conv['conv5_1']]
        self.content_layer = [conv['conv4_2']]

        pass

    def forward(self, x, mode:str):
        #TODO : style, contentë§ˆë‹¤ conv layer slicingí•´ì„œ ì‚¬ìš©í•˜ê¸°
        features = []

        if mode == 'style':
            for i in range(len(self.vgg19_features)):
                x = self.vgg19_features[i](x)
                if i in self.style_layer:
                    features.append(x)

        if mode == 'content':
            for i in range(len(self.vgg19_features)):
                x = self.vgg19_features[i](x)
                if i in self.content_layer:
                    features.append(x)

        return features
```

----------

## loss.py

ë‹¤ìŒìœ¼ë¡œëŠ” lossë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤


----------

## ì„±ëŠ¥ë¹„êµ

